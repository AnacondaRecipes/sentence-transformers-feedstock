{% set name = "sentence-transformers" %}
{% set version = "4.1.0" %}

package:
  name: {{ name|lower }}
  version: {{ version }}

source:
  url: https://github.com/UKPLab/{{ name }}/archive/refs/tags/v{{ version }}.tar.gz
  sha256: 45c3874d1a504ad28ae2f1506589132a4f1ef4378be7271654e4a2db5d9a5b9a

build:
  skip: True  # [py<39]
  number: 0
  script: {{ PYTHON }} -m pip install . -vv --no-deps --no-build-isolation

requirements:
  host:
    - pip
    - python
    - wheel
    - setuptools
  run:
    - python
    - transformers >=4.41.0,<5.0.0
    - tqdm
    - pytorch >=1.11.0
    - scikit-learn
    - scipy
    - huggingface_hub >=0.20.0
    - pillow
    - typing_extensions >=4.5.0

test:
  source_files:
    - tests
    - examples
    - pyproject.toml
  imports:
    - sentence_transformers
    - sentence_transformers.datasets
    - sentence_transformers.evaluation
    - sentence_transformers.losses
    - sentence_transformers.models
    - sentence_transformers.models.tokenizer
    - sentence_transformers.readers
  requires:
    - pip
    - pytest
    - datasets
  commands:
    - pip check
    - export PYTORCH_ENABLE_MPS_FALLBACK=1  # [not win]
    - export HF_DATASETS_OFFLINE=1  # [not win]
    - export HF_HUB_OFFLINE=1  # [not win]

    # OSError: We couldn't connect to 'https://huggingface.co' to load this file
    {% set ignore_tests = " --ignore=tests/test_sentence_transformer.py" %}
    {% set ignore_tests = ignore_tests + " --ignore=tests/cross_encoder/test_cross_encoder.py" %}

    # ReadTimeoutError("HTTPSConnectionPool(host='huggingface.co', port=443)
    {% set skip_tests = "test_pretrained" %}
    # huggingface_hub.utils._errors.HfHubHTTPError: 504 Server Error: Gateway Time-out
    {% set skip_tests = skip_tests + " or test_trainer" %}
    # FileNotFoundError: [Errno 2] No such file or directory:  config.json
    {% set skip_tests = skip_tests + " or test_load_with_safetensors" %}
    # TypeError: MPS BFloat16 is only supported on MacOS 14 or newer
    {% set skip_tests = skip_tests + " or test_bfloat16" %}
    # disabling 3rd party backend API dependend tests
    {% set skip_tests = skip_tests + " or test_LabelAccuracyEvaluator or test_train_stsb or test_train_nli or test_model_card_base or test_model_card_data" %}
    # other pack of tests relying on server or cached data
    {% set skip_tests = skip_tests + " or test_simple" %}
    {% set skip_tests = skip_tests + " or test_nanobeir_evaluator" %}
    {% set skip_tests = skip_tests + " or test_loading_model2vec" %}
    {% set skip_tests = skip_tests + " or test_cmnrl_same_grad" %}
    {% set skip_tests = skip_tests + " or test_classifier_dropout_is_set" %}
    {% set skip_tests = skip_tests + " or test_classifier_dropout_default_value" %}
    {% set skip_tests = skip_tests + " or test_load_with_revision" %}
    {% set skip_tests = skip_tests + " or test_rank" %}
    {% set skip_tests = skip_tests + " or test_safe_serialization" %}
    {% set skip_tests = skip_tests + " or test_paraphrase_mining" %}
    {% set skip_tests = skip_tests + " or test_ParaphraseMiningEvaluator" %}
    {% set skip_tests = skip_tests + " or test_TripletEvaluator" %}
    {% set skip_tests = skip_tests + " or test_initialization_with_embedding_weights" %}
    {% set skip_tests = skip_tests + " or test_initialization_with_embedding_dim" %}
    {% set skip_tests = skip_tests + " or test_tokenize" %}
    {% set skip_tests = skip_tests + " or test_forward" %}
    {% set skip_tests = skip_tests + " or test_save_and_load" %}
    {% set skip_tests = skip_tests + " or test_encode_token_embeddings" %}
    {% set skip_tests = skip_tests + " or test_encode_single_sentences" %}
    {% set skip_tests = skip_tests + " or test_encode_normalize" %}
    {% set skip_tests = skip_tests + " or test_encode_tuple_sentences" %}
    {% set skip_tests = skip_tests + " or test_simple_encode" %}

    - pytest -v -k "not ({{ skip_tests }})" {{ ignore_tests }}

about:
  home: https://www.sbert.net
  license: Apache-2.0
  license_family: APACHE
  license_file: LICENSE
  summary: Sentence Embeddings using BERT / RoBERTa / XLNet
  description: |
    This framework provides an easy method to compute dense vector representations for sentences, 
    paragraphs, and images. The models are based on transformer networks like 
    BERT / RoBERTa / XLM-RoBERTa etc. and achieve state-of-the-art performance in various task. 
    Text is embedding in vector space such that similar text is close and can efficiently be 
    found using cosine similarity.
  doc_url: https://pypi.org/project/sentence-transformers
  dev_url: https://github.com/UKPLab/sentence-transformers

extra:
  recipe-maintainers:
    - rluria14
    - oblute
    - ndmaxar
